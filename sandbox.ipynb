{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleKeywordTableIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    ")\n",
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "\n",
    "\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "PINECONE_API_KEY = os.environ['PINECONE_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = 'gcp-starter'\n",
    "index_name = \"baseline-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pinecone.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Upserted vectors: 100%|██████████| 7/7 [00:01<00:00,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# DO NOT RERUN\n",
    "pinecone.init(api_key=PINECONE_API_KEY)\n",
    "vector_store = PineconeVectorStore(\n",
    "    index_name=index_name,\n",
    "    environment=environment\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "dir_path = 'data'\n",
    "documents = SimpleDirectoryReader(dir_path).load_data()\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index.index_struct.index_id = 'patent'\n",
    "query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Data processing refers to the manipulation and analysis of data to extract meaningful information and insights. It involves various techniques and methods to transform raw data into a more useful format. In the context provided, the invention described relates to a new and useful method for processing more input streams in the data processing field. The method aims to increase the amount of throughput analyzed by analysis models, such as neural networks, without sacrificing latency, accuracy, or overall system performance. It achieves this by allowing more measurements to be processed using the same processing architecture, without the need for retraining, hyperparameter adjustment, or hardware upgrades. The method involves receiving a measurement set, identifying measurements of interest, selecting measurements to composite, generating composite measurements, and analyzing a batch of measurements. This method enables the processing of a larger volume of data while maintaining performance and speed.', source_nodes=[NodeWithScore(node=TextNode(id_='15eb25a9-c5bd-405e-9673-38bade9f09bd', embedding=None, metadata={'file_name': 'AMBI-P06-PRV TXT FILE ME.docx'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='76eaa04f-4f1e-4c2d-be1d-aae5d095071d', node_type=None, metadata={'file_name': 'AMBI-P06-PRV TXT FILE ME.docx'}, hash='838fee2670504f7da583177e516837593c9fa15cfb44c49eed5f51b4713f98e6'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='5690d67b-df29-4a9d-9609-8d4a79023f78', node_type=None, metadata={'file_name': 'AMBI-P06-PRV TXT FILE ME.docx'}, hash='66ce1ad75ce7d91d19d6b8c35ada79eba03fd1b0a5d797b672502b7ac65a0819')}, hash='843c4f4d573f13da1fcfe16256b847efa4b26735771bd646d317760bf8034dc0', text='AMBI-P06-PRV\\n\\n\\n\\n\\t\\t\\n\\n\\t\\n\\n\\tDATA ANALYSIS METHOD AND SYSTEM\\n\\n\\t\\n\\n\\tTECHNICAL FIELD\\n\\n\\tThis invention relates generally to the data processing field, and more specifically to a new and useful method for processing more input streams in the data processing field.BACKGROUND\\n\\n\\tIt is oftentimes advantageous to dynamically increase the amount of throughput analyzed by analysis models, such as neural networks.This is oftentimes done by increasing the batch size at inference.However, this increased throughput can come at the expense of latency and/or accuracy, which, in real-time use cases, can be extremely detrimental to overall system performance.Thus, there is a need in the data processing field to create a new and useful system and method to increase throughput s with lossless or comparable model performance.This invention provides such new and useful system and method.BRIEF DESCRIPTION OF THE FIGURES\\n\\n\\tFIGURE 1 is a flowchart representation of the method.FIGURE 2 is an example of the system and method.FIGURE 3 is an illustrative example of the method.FIGURE 4 is a flowchart representation of an illustrative example of the method.DESCRIPTION OF THE PREFERRED EMBODIMENTS \\n\\n\\tThe following description of the preferred embodiments of the invention is not intended to limit the invention to these preferred embodiments, but rather to enable any person skilled in the art to make and use this invention.As shown in FIGURE 1, the method to scale model inputs can include: receiving a measurement set S100; optionally identifying measurements of interest from the measurement set S200; selecting measurements to composite S300; generating composite measurements from the selected measurements S400; and analyzing a batch of measurements including composited and uncomposited measurements S500.The method functions to allow more measurements (e.g., examples) to be processed using the same processing architecture, without retraining, hyperparameter adjustment, and/or hardware upgrades, while maintaining the same or similar performance (e.g., recall, precision, accuracy) and speed.Additionally or alternatively, this method can enable a machine with fixed computational resources (e.g., capable of processing only U computational units per unit time) to concurrently process more than U units of data (e.g., N images), while preserving or maximizing the quality of the output at each timestep.In an example, shown in FIGURE 4, the method includes: receiving a set of N images; filtering out images satisfying a filtering condition (e.g., amount of activity detected in the scene is less than a predetermined threshold); determining the number of remaining images within the set (C); optionally determining a batch size (B) for the analysis model; determining a number of images to select for composition (or proportion of the remaining images to composite) based on the number of remaining images (C) and the  batch size of the trained analysis model (B); selecting up to or at least the number of images from the remaining images; downscaling the selected images; generating a set of composite images (multiplexed images), each formed from a grid of downscaled images (e.g., grid of 4 downscaled images); optionally batching the composite images and the remaining (uncomposited) images, wherein the resultant batch size is equal to or less than the  batch size of the trained analysis model; and providing the batched images to the analysis model for analysis.In this example, the batch size (B) can be smaller than N, smaller than C, and/or otherwise related to the image set.In specific examples, image filtering and/or image selection for composition can be performed using the metadata associated with the respective image, which can expedite the respective processes.The method can be performed using a system, including: a sensor system and a central processing system, example shown in FIGURE 2.However, the system can include other components.The system functions to monitor and analyze a monitored space, but can be otherwise used.A different system instance (and method instance) is preferably used for each monitored space; alternatively, the same system instance, component instance, and/or method instance can be used for multiple monitored spaces (e.g., the same central processing system can be used to determine safety events for multiple spaces).The sensor system functions to sample measurements of a monitored scene, and can optionally generate metadata for each measurement.The system preferably includes multiple sensor systems (e.g., N sensor systems), but can alternatively include a single sensor system, or any suitable number of sensor systems.The sensor systems can be distributed within a monitored space (e.g., physical space), and monitor the same or different monitored scene.Each sensor system preferably generates a single measurement timeseries (e.g., stream, etc.), but can alternatively generate multiple measurement timeseries.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.405383587), NodeWithScore(node=TextNode(id_='629708f6-15d3-49d1-a402-b9d4f51e93fa', embedding=None, metadata={'file_name': 'AMBI-P06-PRV TXT FILE ME.docx'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='76eaa04f-4f1e-4c2d-be1d-aae5d095071d', node_type=None, metadata={'file_name': 'AMBI-P06-PRV TXT FILE ME.docx'}, hash='838fee2670504f7da583177e516837593c9fa15cfb44c49eed5f51b4713f98e6'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5690d67b-df29-4a9d-9609-8d4a79023f78', node_type=None, metadata={'file_name': 'AMBI-P06-PRV TXT FILE ME.docx'}, hash='66ce1ad75ce7d91d19d6b8c35ada79eba03fd1b0a5d797b672502b7ac65a0819'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='c04798ad-8bf5-403c-89f7-16908e699a56', node_type=None, metadata={'file_name': 'AMBI-P06-PRV TXT FILE ME.docx'}, hash='d3c6cdca98991bcb63f9383d430722425417314bcbab048f2921b93a6230ca21')}, hash='efffe4e6b5e7fac69b5a6fbf1d8c747992c33123ba8b3794fc11c9d316dd59ef', text=\"In the latter variant, the method can optionally crop, resize, infill, or otherwise process the measurements to consolidate the measurement characteristics.S100 can optionally include determining metadata for each measurement.The metadata is preferably determined by and received from the source sensor system generating the measurement (example shown in FIGURE 3), but can alternatively be determined by a set of metadata extraction modules executed by the central processing system, be retrieved (e.g., based on the source sensor system identifier), and/or be determined by any other suitable system.Examples of metadata that can be associated with each measurement can include: the measurement characteristics (e.g., aspect ratio, resolution, point density, etc.), whether motion was detected, motion amount, timestamp, sensor identifier, whether an object was detected, detected object class, whether an activity was detected, detected activity class, interactions (e.g., between detected objects or entities), change across frames (e.g., sitting down to standing up), associated calendar events, measurement stream history (e.g., short term history, such as within the last 30s, 1min, 10mins, etc.; long term history, such as the last day, month, 3 months, year, etc.), historical patterns (e.g., minimum, maximum, average, or other statistical summary of the number of incidents detected from the measurement stream for a given time of day, day of week, week of year, etc.), scene history (e.g., short term history, long term history, etc.), security event history (e.g., short term history, long term history, etc.), reappearance of agents (e.g., users, vehicles, entities, etc.)on physically and/or temporally adjacent streams, agent parameters (e.g., extracted from the measurement stream, etc.), sensor context (e.g., physical location, monitored object or region class, etc.), scene type or environmental context (e.g., kitchen, front door, back door), ambient environment changes (e.g., lighting change exceeding a threshold, acoustic change exceeding a threshold, etc.), and/or other metadata.Optionally identifying measurements of interest from the measurement set S200 functions to reduce the set of measurements to process in S500.A measurement of interest can be a measurement that has an above-threshold probability of depicting information indicative of an event of interest (e.g., security event); a measurement associated with a predetermined set of metadata values; and/or be otherwise defined.The measurements are preferably identified based on their respective metadata values (example shown in FIGURE 3), but can alternatively be identified based on: the measurement value, the context associated with the source sensor (e.g., measurements of an entryway are more frequently included in the resultant set and measurements of a drain pipe are less frequently included in the resultant set, etc.), time since measurements from the source sensor were run at full resolution (e.g., wherein the probability of analyzing a measurement at full resolution increases with time since a prior measurement from the same stream was analyzed at full resolution), and/or other parameters.S200 is preferably performed by a filtering module (examples shown in FIGURE 2 and FIGURE 3), but can be performed by another processing system.The filtering module can be a binary threshold filter that includes or excludes measurements from a filtered set based on whether the respective metadata or measurement value satisfies a predetermined threshold or condition, or otherwise filter the measurement set.The inclusion or exclusion parameters (filtering parameters, filtering conditions) can be specified: automatically; based on the use case (e.g., motion detection for a security system); based on the sensor system's environmental context (e.g., motion detection for streams from a camera monitoring an interior environment; object detection for streams from a camera monitoring an external environment); manually; or otherwise determined.In a first example, an activity filter is used to filter out measurements with less than a threshold amount of motion in the monitored scene.In a second example, the filtering module can retain measurements that have changed between timesteps and/or filter out measurements that have not changed between timesteps (e.g., by comparing hashes of images output by the same sensor).However, S200 can be otherwise performed.Selecting measurements to composite S300 functions to pick a subset of the (resultant) measurement set for composition (e.g., multiplexing).The measurements can be selected from the resultant measurement set from S200 (filtered set, example shown in FIGURE 2 and FIGURE 3), the measurement set received from the sensor systems, and/or from any other suitable set of measurements.\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.477377057)], metadata={'15eb25a9-c5bd-405e-9673-38bade9f09bd': {'file_name': 'AMBI-P06-PRV TXT FILE ME.docx'}, '629708f6-15d3-49d1-a402-b9d4f51e93fa': {'file_name': 'AMBI-P06-PRV TXT FILE ME.docx'}})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.query('tell me about data processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patentai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
